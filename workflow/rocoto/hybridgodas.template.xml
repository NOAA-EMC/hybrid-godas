<?xml version="1.0"?>
<!DOCTYPE workflow
[
<!--================================================================================
  NCEP Hybrid-GODAS
    rocoto XML workflow configuration file
    generated from hybridgodas.template.xml
================================================================================-->


<!-- experiment specific parameters -->
<!ENTITY ROOT_GODAS_DIR        "${ROOT_DIR}">
<!ENTITY ROOT_EXP_DIR          "${EXP_DIR}">
<!ENTITY EXP_NAME              "${EXP_NAME}">
<!ENTITY ENS_LIST_FCST         "${ENS_LIST_FCST}">
<!ENTITY ENS_LIST_DA           "${ENS_LIST_DA}">


<!-- forecast/da parameters -->
<!ENTITY CYCLEDEF "
 ${CYCLEDEF}
">
<!ENTITY DA_SLOTS         "${DA_SLOTS}">


<!-- machine /scheduler specific parameters -->
<!-- TODO: move these to a system config file -->
<!ENTITY PPN                       "36">
<!ENTITY SCHED                     "moab">
<!ENTITY SCHED_ACCT                "${SCHED_ACCT}">
<!ENTITY SCHED_S_QUEUE             "ldtn">
<!ENTITY SCHED_S_ARGS              "-l partition=es">
<!ENTITY SCHED_P_QUEUE             "${SCHED_QUEUE}">
<!ENTITY SCHED_P_ARGS              "-l partition=c4">


<!ENTITY fcst.prep.WALLTIME        "20:00">

<!ENTITY fcst.run.NODES            "20">
<!ENTITY fcst.run.SCHED_ARGS       "&SCHED_P_ARGS; -l size=&fcst.run.NODES;">
<!ENTITY fcst.run.WALLTIME         "20:00">

<!ENTITY da.prep.WALLTIME          "10:00">
<!ENTITY da.prep.3dvar.WALLTIME    "5:00">

<!ENTITY da.3dvar.run.NODES        "2">
<!ENTITY da.3dvar.run.SCHED_ARGS   "&SCHED_P_ARGS; -l size=&da.3dvar.run.NODES;">
<!ENTITY da.3dvar.run.WALLTIME     "10:00">

<!ENTITY da.letkf.run.NODES        "4">
<!ENTITY da.letkf.run.SCHED_ARGS   "&SCHED_P_ARGS; -l size=&da.letkf.run.NODES;">
<!ENTITY da.letkf.run.WALLTIME     "10:00">

<!ENTITY da.update.WALLTIME        "20:00">

<!ENTITY da.post.WALLTIME          "20:00">





<!--============================================================-->
<!-- "shouldn't" need to edit anything below here -->
<!--============================================================-->

<!-- only parameters that should NEVER need to be changed are included below.
     Other user configurable environment variables that rocoto doesnt need to know about
     may be found in the experiment and system configuration files that are loaded by 
     the jobwrapper.sh script that is run before each job -->


<!-- rocoto parameters -->
<!ENTITY MAXTRIES       "2">
<!ENTITY MAXCYCLES      "2">


<!-- cycle info -->
<!ENTITY CYCLE           "<cyclestr>@Y@m@d@H</cyclestr>">
<!ENTITY CYCLE_Z         "<cyclestr>@Y@m@dZ@H</cyclestr>">


<!-- fixed directory locations -->
<!ENTITY EXE_DIR         "&ROOT_GODAS_DIR;/build">
<!ENTITY SCRIPT_DIR      "&ROOT_GODAS_DIR;/run/subscripts">
<!ENTITY SCRIPT_WRAPPER  "source &ROOT_GODAS_DIR;/run/rocoto/jobwrapper.sh;">


<!-- generated output directory locations -->
<!ENTITY LOG_DIR         "&ROOT_EXP_DIR;/log">
<!ENTITY LOG_PREFIX      "&LOG_DIR;/<cyclestr>@Y/@Y@m@d@H/</cyclestr>">
<!ENTITY LOG_PREFIX_ENS  "&LOG_DIR;/<cyclestr>@Y/@Y@m@d@H/mem_#mem#/</cyclestr>">
<!ENTITY RST_DIR         "&ROOT_EXP_DIR;/fcst_rst/mem_#mem#/&#37;Y&#37;m&#37;d&#37;H">


<!-- generated temporary directory locations -->
<!ENTITY WORK_DIR         "${WORK_DIR}/cycle_&CYCLE;">


<!-- common scheduler blocks-->
<!ENTITY COM_SCHED_S  "
  <account>&SCHED_ACCT;</account>
  <queue>&SCHED_S_QUEUE;</queue>
  <cores>1</cores>
  <native>&SCHED_S_ARGS;</native>
">


<!-- common environment blocks -->
<!ENTITY COM_ENV "
  <envar>
    <name>ROOT_GODAS_DIR</name>
    <value>&ROOT_GODAS_DIR;</value>
  </envar>
  <envar>
    <name>ROOT_EXP_DIR</name>
    <value>&ROOT_EXP_DIR;</value>
  </envar>
  <envar>
    <name>CYCLE</name>
    <value>&CYCLE;</value>
  </envar>
  <envar>
    <name>EXE_DIR</name>
    <value>&EXE_DIR;</value>
  </envar>
">

]>



<!--================================================================================-->
<!-- 
Depending on what type of data assimilation we are doing:
 "none" (No DA, just a forced model run, obsop is still calculated though)
 "var"  (3DVar only)
 "ekf"  (LETKF only)
 "hyb"  (LETKF/3DVAR hybrid)

the following steps are performed:
 * fcst.prep
 * fcst.run
 * da.prep
 * da.letkf.run   (hyb/ekf only)
 * da.prep.3dvar  (hyb     only)
 * da.3dvar.run   (hyb/var only)
 * cycle.post
-->
<!--================================================================================-->


<workflow realtime="F" scheduler="&SCHED;" cyclethrottle="&MAXCYCLES;">

  &CYCLEDEF;
  <log verbosity="10">&LOG_PREFIX;workflow.log</log>



  <!--********************************************************************************
    fcst.prep - Surface forcing preparation

      * Prepares ensemble surface forcings
      * (This can be run 1 or more cycles ahead, as it doesn't require the previous
         cycle to have finished)
   ********************************************************************************-->
  <task name="fcst.prep" maxtries="&MAXTRIES;">

    <jobname>&EXP_NAME;.fcst.prep</jobname>
    <join>&LOG_PREFIX;fcst.prep.log</join>
    <walltime>&fcst.prep.WALLTIME;</walltime>
    &COM_SCHED_S;


    <command>
      &SCRIPT_WRAPPER;
      &SCRIPT_DIR;/fcst.prep.sh
    </command>


    &COM_ENV;
    <envar>
      <name>JOB_WORK_DIR</name>
      <value>&WORK_DIR;/fcst.prep</value>
    </envar>    
  </task>




  <!--********************************************************************************
    fcst.run - MOM6 model run

      * Runs the ensemble of MOM6 forecasts
      * if there was a previous cycle doing DA, and thus generate an analysis
        increment, that increment is applied to the restart file before running
      * NOTE: the FCST_RESTART env var is specially set here indicating a restart
        should be performed unless the "cycle/cycle.status" file contains "init:$CYLCE"
   ********************************************************************************-->
  <metatask name="fcst.run.all">
    <var name="mem">&ENS_LIST_FCST;</var>
    <task name="fcst.run.#mem#" maxtries="&MAXTRIES;">
     
      <jobname>&EXP_NAME;.fcst.run.#mem#</jobname>
      <join>&LOG_PREFIX_ENS;fcst.run.#mem#.log</join>
      <walltime>&fcst.run.WALLTIME;</walltime>
      <account>&SCHED_ACCT;</account>
      <queue>&SCHED_P_QUEUE;</queue>
      <nodes>&fcst.run.NODES;:ppn=&PPN;</nodes>
      <native>&fcst.run.SCHED_ARGS;</native>


      <command>
        &SCRIPT_WRAPPER;

	# where are the restart files saved?
	export RST_DIR_IN=&ROOT_EXP_DIR;/cycle/&#36;CYCLE/rst/mem_#mem#/
	export RST_DIR_OUT=&ROOT_EXP_DIR;/cycle/&#36;CYCLE_NEXT/rst/mem_#mem#/
	export MEM=#mem#
	# update the restart files if we did DA in previous cycle
	export FCST_RESTART=$([[ $(cat cycle/cycle.status) == "ini:&CYCLE;" ]] &#38;&#38; echo 0 || echo 1)
	if [[ &#36;FCST_RESTART -eq 1 &#38;&#38; ! &#36;DA_MODE == "none" ]]; then 
  	  export JOB_WORK_DIR=&WORK_DIR;/fcst.rst/mem_#mem#
	  time &SCRIPT_DIR;/da.update.sh
	  export RST_DIR_IN=&WORK_DIR;/fcst.rst/mem_#mem#
	fi

	# run the forecast
	export FCST_DIAG_DA=1
	export FCST_DIAG_OTHER=0
	if [[ #mem# == "0000" ]]; then
	    export FCST_DIAG_OTHER=1
	fi
        &SCRIPT_DIR;/fcst.run.sh

	# this is the end of the cycle, if not doing DA
	if [[ &#36;DA_MODE == "none" ]]; then echo "rst:&#36;CYCLE_NEXT" > &#36;ROOT_EXP_DIR/cycle/cycle.status; fi

      </command>


      &COM_ENV;
      <envar>
	<name>NODES</name>
	<value>&fcst.run.NODES;</value>
      </envar>
      <envar>
	<name>PPN</name>
	<value>&PPN;</value>
      </envar>
      <envar>
	<name>FCST_DIR</name>
	<value>&WORK_DIR;/fcst.run/mem_#mem#</value>
      </envar>          
      <envar>
	<name>FORC_DIR</name>
	<value>&WORK_DIR;/fcst.prep/mem_#mem#</value>
      </envar>    
      
      <dependency>
	<and>
	  <taskdep task="fcst.prep"/>
	  <rb>
	    <!-- must be the first date of a cycle, or previous analysis must have finished -->
	    f = "&ROOT_EXP_DIR;/cycle/cycle.status"
	    d=File.open(f,"r").gets.strip[4,10]
	    d == ymdh || d == "&CYCLE;"
	  </rb>
	</and>
      </dependency>

    </task>
  </metatask>




  <!--********************************************************************************
    da.prep - data assimilation preparation

      * Combines the MOM6 daily output file tiles into single files
        (TODO: remove this step and let the obsop handle tiles directly)
      * performs various observations operators for given ensemble member / timeslot
      * (setup to do either ALL timeslots as a single job (var "slot" set to "_all" below)
        or each timeslot as a separate job (var "slot" set to "&DA_SLOTS;" below))
      * Combines the obsop output from all slots for each member
      * Combines the MOM6 restart file tiles if we are doing DA
   ********************************************************************************--> 
  <metatask name="da.prep.all">
    <!-- <var name="slot">&DA_SLOTS;</var> -->
    <var name="slot">_all</var> 

    <metatask name="da.prep.t#slot#.allmem">
      <var name="mem">&ENS_LIST_FCST;</var>
      <task name="da.prep.t#slot#.#mem#" maxtries="&MAXTRIES;">

	<jobname>&EXP_NAME;.da.prep.t#slot#.#mem#</jobname>
	<join>&LOG_PREFIX_ENS;da.prep.t#slot#.#mem#.log</join>
	<walltime>&da.prep.WALLTIME;</walltime>
	&COM_SCHED_S;


	<command>
	  &SCRIPT_WRAPPER;

	  # combine the forecast daily files and run the obsop on it
	  slots="#slot#"
	  if [[ "&#36;slots" = "_all" ]]; then
	    slots="&DA_SLOTS;"; 
	  else
	    exit 1 #TODO, fix this, allow for multiple da.prep jobs, one
                   # for each slot of each member
	  fi    
	  for s in &#36;slots; do
	    export DA_SLOT=&#36;s
	    export OBSOP_FILE=${OBSOP_FILE_TMPL//&#37;slot/&#36;s}
	    &SCRIPT_DIR;/fcst.comb.slot.sh
  	    export JOB_WORK_DIR=&WORK_DIR;/da.prep/omf/work.slots/mem_#mem#/t&#36;s
	    &SCRIPT_DIR;/da.obsop.slot.sh
	  done

	  # combine all the obsop slots into a single file
	  export JOB_WORK_DIR=&WORK_DIR;/da.prep/omf/work.cmb/mem_#mem#
	  export OMF_FILES=&WORK_DIR;/da.prep/omf/mem_#mem#/t*.nc
	  export OUT_FILE=&WORK_DIR;/da.prep/omf/mem_#mem#/obs.nc
	  &SCRIPT_DIR;/da.obsop.comb.sh

	  # only need to combine the restart file if we are actually doing DA
	  if [[ ! &#36;DA_MODE == "none" ]]; then
	    export RST_COMB_DIR=&ROOT_EXP_DIR;/cycle/&#36;CYCLE_NEXT/rst_comb/mem_#mem#/
	    &SCRIPT_DIR;/fcst.comb.rst.sh
	  fi	    
	</command>


	&COM_ENV;
	<envar>
	  <name>FCST_DIR</name>
	  <value>&WORK_DIR;/fcst.run/mem_#mem#</value>
	</envar>
	<envar>
	  <name>BKG_FILE</name>
	  <value>&WORK_DIR;/da.prep/bkg/mem_#mem#/&#37;Y&#37;m&#37;d.nc</value>
	</envar>	  
	<envar>
	  <name>OBSOP_FILE_TMPL</name>
	  <value>&WORK_DIR;/da.prep/omf/mem_#mem#/t&#37;slot.nc</value>
	</envar>
	<envar>
	  <name>BKG_RST_DIR</name>
	  <value>&WORK_DIR;/da.prep/bkg_rst/mem_#mem#</value>
	</envar>
	<envar>
	  <name>ANA_RST_DIR</name>
	  <value>&WORK_DIR;/da.prep/ana_rst/mem_#mem#</value>
	</envar>	  
	
	<dependency>
	    <taskdep task="fcst.run.#mem#"/>
	</dependency>
	
      </task>
    </metatask>
  </metatask>





  <!--********************************************************************************
    da.letkf.run  - LETKF Data assimilation

      * does the LETKF, obviously
   ********************************************************************************-->
  ${IF_S_LETKF}
  <task name="da.letkf.run" maxtries="&MAXTRIES;">

    <jobname>&EXP_NAME;.da.letkf.run</jobname>
    <join>&LOG_PREFIX;da.letkf.run.log</join>
    <walltime>&da.letkf.run.WALLTIME;</walltime>
    <account>&SCHED_ACCT;</account>
    <queue>&SCHED_P_QUEUE;</queue>
    <nodes>&da.letkf.run.NODES;:ppn=&PPN;</nodes>
    <native>&da.letkf.run.SCHED_ARGS;</native>


    <command>
      &SCRIPT_WRAPPER;

      export ANA_FILES=&ROOT_EXP_DIR;/cycle/&#36;CYCLE_NEXT/da.letkf/
      &SCRIPT_DIR;/da.letkf.run.sh

      # this is the end of the cycle if only doing LETKF
      if [[ &#36;DA_MODE == "ekf" ]]; then echo "rst:&#36;CYCLE_NEXT" > &#36;ROOT_EXP_DIR/cycle/cycle.status; fi
    </command>


    &COM_ENV;
    <envar>
      <name>TMP_DIR</name>
      <value>&WORK_DIR;/da.letkf</value>
    </envar>
    <envar>
      <name>NODES</name>
      <value>&da.letkf.run.NODES;</value>
    </envar>
    <envar>
      <name>PPN</name>
      <value>&PPN;</value>
    </envar>
    <envar>
      <name>ENS_LIST</name>
      <value>&ENS_LIST_DA;</value>
    </envar>

    <dependency>
	<metataskdep metatask="da.prep.all"/>
    </dependency>

  </task>
  ${IF_E_LETKF}




  <!--********************************************************************************
    da.3dvar.prep  -  3DVar Data assimilation preparation 

      * this is ONLY done if doing hybrid LETKF/3DVAR DA, otherwise the 3DVar 
        will just use the output of the da.prep step
      * performs observation operator on the analysis mean output from the LETKF
   ********************************************************************************-->
  ${IF_S_HYB}
  <task name="da.prep.3dvar" maxtries="&MAXTRIES;">

    <jobname>&EXP_NAME;.da.prep.3dvar</jobname>
    <join>&LOG_PREFIX;da.prep.3dvar.log</join>
    <walltime>&da.prep.3dvar.WALLTIME;</walltime>
    &COM_SCHED_S;


    <command>
      &SCRIPT_WRAPPER;

      # combine the forecast daily files and run the obsop on it
      slots="_all"
      if [[ "&#36;slots" = "_all" ]]; then
        slots="&DA_SLOTS;";
      else
	exit 1 #TODO, fix this
      fi
      for s in &#36;slots; do
        export DA_SLOT=&#36;s
	export JOB_WORK_DIR=&WORK_DIR;/da.prep.3dvar/omf/work.slots/t&#36;s
	export OBSOP_FILE=${OBSOP_FILE_TMPL//&#37;slot/&#36;s}
	&SCRIPT_DIR;/da.obsop.slot.sh
      done

      # combine all the obsop slots into a single file
      export JOB_WORK_DIR=&WORK_DIR;/da.prep.3dvar/omf/work.cmb/
      export OMF_FILES=&WORK_DIR;/da.prep.3dvar/omf/t*.nc
      export OUT_FILE=&WORK_DIR;/da.prep.3dvar/omf/obs.nc
      &SCRIPT_DIR;/da.obsop.comb.sh
    </command>


    &COM_ENV;
    <envar>
      <name>BKG_FILE</name>
      <value>&WORK_DIR;/da.letkf/OUTPUT/ana_mean.nc</value>
    </envar>
    <envar>
      <name>OBSOP_FILE_TMPL</name>
      <value>&WORK_DIR;/da.prep.3dvar/omf/t&#37;slot.nc</value>
    </envar>

    <dependency>
      <and>
	<metataskdep metatask="da.prep.all"/>
	<taskdep task="da.letkf.run"/>
      </and>
    </dependency>

  </task>
  ${IF_E_HYB}




  <!--********************************************************************************
    da.3dvar.run  -  3DVar data assimilation

      * Runs the 3dvar preparation (bgvar /vtloc programs)
      * Runs the 3dvar and generates an analysis increment
   ********************************************************************************-->
  ${IF_S_3DVAR}
  <task name="da.3dvar.run" maxtries="&MAXTRIES;">

    <jobname>&EXP_NAME;.da.3dvar.run</jobname>
    <join>&LOG_PREFIX;da.3dvar.run.log</join>
    <walltime>&da.3dvar.run.WALLTIME;</walltime>
    <account>&SCHED_ACCT;</account>
    <queue>&SCHED_P_QUEUE;</queue>
    <nodes>&da.3dvar.run.NODES;:ppn=&PPN;</nodes>
    <native>&da.3dvar.run.SCHED_ARGS;</native>


    <command>
      &SCRIPT_WRAPPER;

      # determine where to pull the obs and bkg from
      if [[ &#36;DA_MODE == "var" ]]; then
        export OBS_FILE=&WORK_DIR;/da.prep/omf/mem_&ENS_LIST_DA;/obs.nc
	export BKG_FILE=&WORK_DIR;/da.prep/bkg_rst/mem_&ENS_LIST_DA;/MOM.res.nc
      else # hyb
        export OBS_FILE=&WORK_DIR;/da.prep.3dvar/omf/obs.nc
	export BKG_FILE=&WORK_DIR;/da.letkf/OUTPUT/ana_mean.nc
      fi      
      export AI_FILE=&ROOT_EXP_DIR;/cycle/&#36;CYCLE_NEXT/da.3dvar/ai.nc

      # run 3DVar
      &SCRIPT_DIR;/da.3dvar.run.sh


      # this is the end of the cycle
      echo "rst:&#36;CYCLE_NEXT" > &#36;ROOT_EXP_DIR/cycle/cycle.status

    </command>


    &COM_ENV;
    <envar>
      <name>NODES</name>
      <value>&da.3dvar.run.NODES;</value>
    </envar>
    <envar>
      <name>PPN</name>
      <value>&PPN;</value>
    </envar>
    <envar>
      <name>TMP_DIR</name>
      <value>&WORK_DIR;/da.3dvar</value>
    </envar>

    
    <dependency>
      <and>
	<metataskdep metatask="da.prep.all"/>
	${IF_S_3DVAR_HYB}
	<taskdep task="da.prep.3dvar"/>
	${IF_E_3DVAR_HYB}
      </and>
    </dependency>

  </task>
  ${IF_E_3DVAR}


  <!--********************************************************************************
    cycle.post  -  end of cycle post processing

      * Performs other file manipulations for things that want to be saved
        (file compression, etc.)
      * cleans up files that are no longer needed
      * This does not need to finsish before rocoto can move onto the next cycle
   ********************************************************************************-->
  <task name="cycle.post" maxtries="&MAXTRIES;">

    <jobname>&EXP_NAME;.cycle.post</jobname>
    <command>
      &SCRIPT_WRAPPER;
      &SCRIPT_DIR;/cycle.post.sh
      echo "&#36;{CYCLE:0:10}" > &#36;ROOT_EXP_DIR/cycle/cycle_post.status
    </command>
    <join>&LOG_PREFIX;cycle.post.log</join>
    <walltime>&da.post.WALLTIME;</walltime>
    &COM_SCHED_S;

    &COM_ENV;
    <envar>
      <name>JOB_WORK_DIR</name>
      <value>&WORK_DIR;</value>
    </envar>
    <envar>
      <name>ENS_LIST</name>
      <value>&ENS_LIST_DA;</value>
    </envar>
    
    <dependency>
      <and>
	<metataskdep metatask="da.prep.all"/>
	${IF_S_3DVAR} <taskdep task="da.3dvar.run"/> ${IF_E_3DVAR}
	${IF_S_LETKF} <taskdep task="da.letkf.run"/> ${IF_E_LETKF}
      </and>
    </dependency>
  </task>


</workflow>
